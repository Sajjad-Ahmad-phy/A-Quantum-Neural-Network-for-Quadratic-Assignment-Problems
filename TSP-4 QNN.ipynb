{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ed0c7e7-9923-48ab-8e40-c7576e0f9837",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Simulating the travelling salesman problem with three cities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d5605-c967-4a8d-8601-c7bfcfd859fb",
   "metadata": {},
   "source": [
    "* Importing important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc188acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import *\n",
    "from qiskit.circuit import parameter\n",
    "from qiskit.circuit import ParameterVector, Parameter\n",
    "from qiskit.visualization import plot_histogram\n",
    "from IPython.core.display import Latex\n",
    "from qiskit_algorithms.optimizers import ADAM, COBYLA\n",
    "from qiskit_algorithms.gradients import SPSAEstimatorGradient\n",
    "from qiskit_aer import Aer, AerSimulator, StatevectorSimulator\n",
    "from sympy.physics.quantum import TensorProduct\n",
    "from sympy import Matrix\n",
    "import matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from qiskit.circuit.library.standard_gates import RXGate, RYGate, RZGate, RZZGate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510c869",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### n-cycle adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a53f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency_matrix(V, edges):\n",
    "    # Initialize an empty V x V matrix with all zeros\n",
    "    matrix = [[0] * V for _ in range(V)]\n",
    "    \n",
    "    # Populate the matrix based on the edges\n",
    "    for edge in edges:\n",
    "        u, v = edge\n",
    "        matrix[u][v] = 1\n",
    "        matrix[v][u] = 1  # Undirected graph\n",
    "    \n",
    "    return np.array(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29986810",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Cost Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b750e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSP- 4 distance matrix\n",
    "D = np.array([[0.        ,0.54194679,0.58401706,0.19804715],\n",
    " [0.54194679,0.        ,0.77658693,0.43439787],\n",
    " [0.58401706,0.77658693,0.        ,0.73731612],\n",
    " [0.19804715,0.43439787,0.73731612,0.        ]])\n",
    "\n",
    "\n",
    "'Number of Nodes'\n",
    "V = 4\n",
    "edges = [(0, 1), (1, 2), (2, 3), (3, 0)]\n",
    "\n",
    "'Adjacency matrix'\n",
    "A = adjacency_matrix(V, edges)\n",
    "\n",
    "'Affinity matrix'\n",
    "K = TensorProduct(A, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de387dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0941c86d",
   "metadata": {},
   "source": [
    "### Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f330131",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "beta_para = 1.39957953\n",
    "theta1 = [1.9026521]\n",
    "theta2 = [2.22944427]\n",
    "alpha = [5.56530919]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb222ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6aab2310",
   "metadata": {},
   "source": [
    "* Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4137feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 3    # Number of cities\n",
    "# beta_para = (2 * np.pi * np.random.rand(1))[0]         # Beta parameters\n",
    "# theta1 = (2 * np.pi * np.random.rand(1))        # Perceptron layers 1st parameters\n",
    "# theta2 =(2 * np.pi * np.random.rand(1))   # Perceptron layers 2nd parameters\n",
    "# alpha = (2 * np.pi * np.random.rand(1))       # Alpha parameters for pooling layer\n",
    "\n",
    "# # initial_point = np.array([beta_para for i in range(n*n)]+[theta1[0] for i in range(n*n)]+\n",
    "# #                          [theta2[0] for i in range(n*n)]+[alpha[0] for i in range(n*n)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7707e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e43cb6da-6d1f-480c-83ff-32d4021dad7b",
   "metadata": {},
   "source": [
    "#### TSP_solver algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "680e08ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSP_Solver:\n",
    "    def __init__(self, reference_circuit, variational_circuit, MCRX, n, K, theta1, theta2, alpha, matching_matrix, loss):\n",
    "        self.ref_cir = reference_circuit\n",
    "        self.var_cir = variational_circuit\n",
    "        self.MCRX = MCRX\n",
    "        self.n = n\n",
    "        self.n1 = n*n  # Squared of number of cities\n",
    "        self.a_m = K   # affinity matrix\n",
    "        self.alpha = alpha\n",
    "        self.theta1 = theta1\n",
    "        self.theta2 = theta2\n",
    "        self.matching_matrix = matching_matrix  # A constraint matrix for matching with the ground truth\n",
    "        self.loss = loss\n",
    "    \n",
    "    \"Creating an object of encoding layer\"\n",
    "    def encoding_layer(self):\n",
    "        self.ref_cir.h([q for q in range(self.n1)])  # Applying Hadammard to all qubits\n",
    "        for i in range(self.n1):\n",
    "            a = 1                     # var a ensures that only upper-traingle's elements are encoded\n",
    "            for j in range(self.n1):\n",
    "                if i == j:\n",
    "                    self.ref_cir.ry(K[i][j], i)\n",
    "                    \n",
    "                elif i != j and i != a:\n",
    "                    self.ref_cir.append(RZZGate(K[i][j]), [i, a])\n",
    "                    a += 1\n",
    "            a += 1\n",
    "\n",
    "    'Function that return the ctrl qubits for constrained layer'\n",
    "    def ctrl_qubits(self, matrix, row_idx, col_idx):\n",
    "        neighbors = []\n",
    "        num_rows = len(matrix)\n",
    "        num_cols = len(matrix[0])\n",
    "\n",
    "        # Add neighbors from the same row\n",
    "        for j in range(num_cols):\n",
    "            if j != col_idx:  # Exclude the element itself\n",
    "                neighbors.append(matrix[row_idx][j])\n",
    "\n",
    "        # Add neighbors from the same column\n",
    "        for i in range(num_rows):\n",
    "            if i != row_idx:  # Exclude the element itself\n",
    "                neighbors.append(matrix[i][col_idx])\n",
    "\n",
    "        return neighbors\n",
    "            \n",
    "    \"Defining contraint layer\"\n",
    "    def constraint_layer(self): \n",
    "        matrix = np.array([i for i in range(self.n*self.n)]).reshape(self.n, self.n)\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.n):  \n",
    "                ctrl = list(self.ctrl_qubits(matrix, i, j))+[matrix[i][j]]\n",
    "                self.var_cir.append(self.MCRX, ctrl)    \n",
    "        self.var_cir.barrier()\n",
    "    \n",
    "    \"Perceptron layer\"\n",
    "    def perceptron_layer(self):\n",
    "        rz = RZGate(self.theta1[0])\n",
    "        ry = RYGate(self.theta2[0])\n",
    "        for q in range(self.n1):\n",
    "            self.var_cir.append(rz, [q])\n",
    "            self.var_cir.append(ry, [q])\n",
    "        self.var_cir.barrier()\n",
    "               \n",
    "    'Pooling Layer'\n",
    "    def pooling_layer(self):\n",
    "        ry = RYGate(self.alpha[0])\n",
    "        for q in range(self.n1):\n",
    "            self.var_cir.append(ry, [q])\n",
    "    \n",
    "    'composing the reference and variational circuits'\n",
    "    # The circuit can be visualized as well from here.\n",
    "    def ansatz(self):\n",
    "        ansat = self.ref_cir.compose(self.var_cir)\n",
    "        ansat.measure_all()\n",
    "        return ansat\n",
    "    \n",
    "    'Statvector simulating'\n",
    "    def statevect(self):\n",
    "        simulator = Aer.get_backend('statevector_simulator')\n",
    "        result = simulator.run(self.ansatz).result()\n",
    "        sv = result.get_statevector()\n",
    "        return sv.draw('latex')\n",
    "    \n",
    "    def sinkhorn_normalization(self, matrix, epsilon=1e-3, max_iters=100, constraint_epsilon=1e-9):\n",
    "        assert matrix.shape[0] == matrix.shape[1], \"Input matrix must be square\"\n",
    "\n",
    "        # Get the shape of the matrix\n",
    "        n = matrix.shape[0]\n",
    "\n",
    "        # Initialize u and v vectors\n",
    "        u = np.ones(n)\n",
    "        v = np.ones(n)\n",
    "\n",
    "        # Perform Sinkhorn iterations\n",
    "        for _ in range(max_iters):\n",
    "            u_new = 1 / (np.dot(matrix, v) + epsilon)\n",
    "            v_new = 1 / (np.dot(matrix.T, u_new) + epsilon)\n",
    "\n",
    "            # Check convergence\n",
    "            if np.allclose(u_new, u) and np.allclose(v_new, v):\n",
    "                break\n",
    "\n",
    "            u = u_new\n",
    "            v = v_new\n",
    "\n",
    "        # Compute the Sinkhorn normalized matrix\n",
    "        normalized_matrix = np.diag(u_new) @ matrix @ np.diag(v_new)\n",
    "\n",
    "        # Apply constraint on zero terms\n",
    "        normalized_matrix[normalized_matrix < constraint_epsilon] = constraint_epsilon\n",
    "\n",
    "        # Renormalize the matrix to ensure it remains doubly stochastic\n",
    "        row_sums = np.sum(normalized_matrix, axis=1)\n",
    "        col_sums = np.sum(normalized_matrix, axis=0)\n",
    "        normalized_matrix /= np.sqrt(np.outer(row_sums, col_sums))\n",
    "\n",
    "        \n",
    "        return normalized_matrix\n",
    "\n",
    "    'Reshaping result to matrix'\n",
    "    def x_matrix(self):\n",
    "        latex_string = self.statevect().data     # Stores the statevector as a latex string5\n",
    "        latex_list = list(latex_string)        # This object stores the statevector as a list\n",
    "        \n",
    "        'Extracting only the states of the qubits'\n",
    "        a = latex_list.index('|')\n",
    "        b = latex_list.index('\\\\')\n",
    "        y = latex_list[a+1:b]\n",
    "        y1 = np.array([int(i) for i in y])\n",
    "        Y1 = y1.reshape(self.n, self.n)  # Reshaping the measured states of qubits to a matrix \n",
    "\n",
    "        # Apply Sinkhorn algorithm to converge to a doubly stochastic matrix with the matching constraint\n",
    "        X_ds = self.sinkhorn_normalization(Y1)\n",
    "        return X_ds\n",
    "    \n",
    "    def cost_fun(self):\n",
    "        \"\"\"Cost function of circuit parameters on training data.\n",
    "            The optimizer will attempt to minimize this.\"\"\"\n",
    "        X = list(self.matching_matrix.flatten())\n",
    "        Y = list(self.x_matrix().flatten())\n",
    "        for i in range(len(X)):\n",
    "            self.loss += (-X[i]*np.log(Y[i]) + (1-X[i])*np.log(1-Y[i]))\n",
    "        return self.loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05abe8f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Calling the whole class here\n",
    "* Number of Cities 'n'\n",
    "* Quantum circuit \n",
    "* Applying Hadammard to all qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f7c17b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def call_pass_obj_fun(TSP):\n",
    "    TSP.encoding_layer()\n",
    "    TSP.constraint_layer()\n",
    "    TSP.perceptron_layer()\n",
    "    TSP.pooling_layer()\n",
    "    TSP.ansatz()\n",
    "    \n",
    "    # return TSP.ansatz().draw('mpl')\n",
    "    TSP.statevect()\n",
    "    TSP.x_matrix()\n",
    "    TSP.cost_fun()\n",
    "    return TSP.loss\n",
    "\n",
    "reference_circuit = QuantumCircuit(n*n)      # Circuit to which data be encoded\n",
    "variational_circuit = QuantumCircuit(n*n)     # Circuit for\n",
    "\n",
    "loss = 0\n",
    "MCRX=RXGate(beta_para).control(6, ctrl_state='000000')\n",
    "\n",
    "TSP = TSP_Solver(reference_circuit, variational_circuit, MCRX, n, K, theta1, theta2, alpha, m_c, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dcc3a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Objective function for optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cebd24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(params):\n",
    "\n",
    "    theta1_values = params[9:18]  # Extract first 9 values for theta1\n",
    "    theta2_values = params[18:27]  # Extract next 9 values for theta2\n",
    "    alpha = params[27:36]  # Extract alpha\n",
    "    beta_para = params[:1]  # Extract beta_para\n",
    "\n",
    "    # Set theta1 and theta2 values\n",
    "    TSP.theta1 = theta1_values\n",
    "    TSP.theta2 = theta2_values\n",
    "    TSP.alpha = alpha\n",
    "\n",
    "    # Update the beta_para for MCRX gate\n",
    "    beta_angle = beta_para[0]  # Assuming you want to use the first value from beta_para\n",
    "    MCRX = RXGate(beta_angle).control(4, ctrl_state='0000')\n",
    "    TSP.MCRX = MCRX\n",
    "    \n",
    "    # Run the quantum neural network and compute loss\n",
    "    obj_loss = call_pass_obj_fun(TSP)\n",
    "    return obj_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728168ee",
   "metadata": {},
   "source": [
    "#### Gradient for the optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd37ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_function(params):\n",
    "\n",
    "    epsilon = 1e-6  # pert value\n",
    "\n",
    "    initial_loss = objective_function(params)\n",
    "\n",
    "    params_plus = params.copy() + 2*epsilon\n",
    "    \n",
    "    loss_plus = objective_function(params_plus)\n",
    "    \n",
    "    gradient = (loss_plus - initial_loss) / 2*epsilon\n",
    "\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5385033f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fffff2d-a2ee-4506-a428-5a7ec0c205ff",
   "metadata": {},
   "source": [
    "#### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5649da24",
   "metadata": {},
   "outputs": [
    {
     "ename": "CircuitError",
     "evalue": "'The amount of qubit(7)/clbit(0) arguments does not match the gate expectation (5).'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCircuitError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m adam_optimizer \u001b[38;5;241m=\u001b[39m ADAM(maxiter\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-06\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m,\n\u001b[0;32m      6\u001b[0m                       beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.99\u001b[39m, noise_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-08\u001b[39m, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-10\u001b[39m, amsgrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, snapshot_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Run optimization\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m result \u001b[38;5;241m=\u001b[39m adam_optimizer\u001b[38;5;241m.\u001b[39mminimize(objective_function, initial_point, gradient_function)\n\u001b[0;32m     10\u001b[0m result\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\qiskit_algorithms\\optimizers\\adam_amsgrad.py:214\u001b[0m, in \u001b[0;36mADAM.minimize\u001b[1;34m(self, fun, x0, jac, bounds)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     jac \u001b[38;5;241m=\u001b[39m Optimizer\u001b[38;5;241m.\u001b[39mwrap_function(Optimizer\u001b[38;5;241m.\u001b[39mgradient_num_diff, (fun, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eps))\n\u001b[1;32m--> 214\u001b[0m derivative \u001b[38;5;241m=\u001b[39m jac(x0)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(np\u001b[38;5;241m.\u001b[39mshape(derivative))\n",
      "Cell \u001b[1;32mIn[32], line 5\u001b[0m, in \u001b[0;36mgradient_function\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient_function\u001b[39m(params):\n\u001b[0;32m      3\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m  \u001b[38;5;66;03m# pert value\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     initial_loss \u001b[38;5;241m=\u001b[39m objective_function(params)\n\u001b[0;32m      7\u001b[0m     params_plus \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mepsilon\n\u001b[0;32m      9\u001b[0m     loss_plus \u001b[38;5;241m=\u001b[39m objective_function(params_plus)\n",
      "Cell \u001b[1;32mIn[31], line 19\u001b[0m, in \u001b[0;36mobjective_function\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     16\u001b[0m TSP\u001b[38;5;241m.\u001b[39mMCRX \u001b[38;5;241m=\u001b[39m MCRX\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Run the quantum neural network and compute loss\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m obj_loss \u001b[38;5;241m=\u001b[39m call_pass_obj_fun(TSP)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj_loss\n",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m, in \u001b[0;36mcall_pass_obj_fun\u001b[1;34m(TSP)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_pass_obj_fun\u001b[39m(TSP):\n\u001b[0;32m      2\u001b[0m     TSP\u001b[38;5;241m.\u001b[39mencoding_layer()\n\u001b[1;32m----> 3\u001b[0m     TSP\u001b[38;5;241m.\u001b[39mconstraint_layer()\n\u001b[0;32m      4\u001b[0m     TSP\u001b[38;5;241m.\u001b[39mperceptron_layer()\n\u001b[0;32m      5\u001b[0m     TSP\u001b[38;5;241m.\u001b[39mpooling_layer()\n",
      "Cell \u001b[1;32mIn[27], line 53\u001b[0m, in \u001b[0;36mTSP_Solver.constraint_layer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn):  \n\u001b[0;32m     52\u001b[0m         ctrl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctrl_qubits(matrix, i, j))\u001b[38;5;241m+\u001b[39m[matrix[i][j]]\n\u001b[1;32m---> 53\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_cir\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMCRX, ctrl)    \n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_cir\u001b[38;5;241m.\u001b[39mbarrier()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\qiskit\\circuit\\quantumcircuit.py:1276\u001b[0m, in \u001b[0;36mQuantumCircuit.append\u001b[1;34m(self, instruction, qargs, cargs)\u001b[0m\n\u001b[0;32m   1273\u001b[0m instructions \u001b[38;5;241m=\u001b[39m InstructionSet(resource_requester\u001b[38;5;241m=\u001b[39mcircuit_scope\u001b[38;5;241m.\u001b[39mresolve_classical_resource)\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;66;03m# For Operations that are non-Instructions, we use the Instruction's default method\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m broadcast_iter \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1276\u001b[0m     operation\u001b[38;5;241m.\u001b[39mbroadcast_arguments(expanded_qargs, expanded_cargs)\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(operation, Instruction)\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m Instruction\u001b[38;5;241m.\u001b[39mbroadcast_arguments(operation, expanded_qargs, expanded_cargs)\n\u001b[0;32m   1279\u001b[0m )\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m qarg, carg \u001b[38;5;129;01min\u001b[39;00m broadcast_iter:\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_dups(qarg)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\qiskit\\circuit\\gate.py:207\u001b[0m, in \u001b[0;36mGate.broadcast_arguments\u001b[1;34m(self, qargs, cargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validation and handling of the arguments and its relationship.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03mFor example, ``cx([q[0],q[1]], q[2])`` means ``cx(q[0], q[2]); cx(q[1], q[2])``. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m        arguments does not match the gate expectation.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(qargs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_qubits \u001b[38;5;129;01mor\u001b[39;00m cargs:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CircuitError(\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe amount of qubit(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(qargs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)/clbit(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cargs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) arguments does\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not match the gate expectation (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_qubits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    210\u001b[0m     )\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m qarg \u001b[38;5;28;01mfor\u001b[39;00m qarg \u001b[38;5;129;01min\u001b[39;00m qargs):\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CircuitError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne or more of the arguments are empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mCircuitError\u001b[0m: 'The amount of qubit(7)/clbit(0) arguments does not match the gate expectation (5).'"
     ]
    }
   ],
   "source": [
    "\n",
    "initial_point = np.array([beta_para for i in range(n*n)]+[theta1[0] for i in range(n*n)]+\n",
    "                         [theta2[0] for i in range(n*n)]+[alpha[0] for i in range(n*n)])\n",
    "\n",
    "# Instantiate Adam optimizer\n",
    "adam_optimizer = ADAM(maxiter= 5, tol=1e-06, lr=0.1, beta_1=0.9,\n",
    "                      beta_2=0.99, noise_factor=1e-08, eps=1e-10, amsgrad=False, snapshot_dir=None)\n",
    "\n",
    "# Run optimization\n",
    "result = adam_optimizer.minimize(objective_function, initial_point, gradient_function)\n",
    "result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabbf2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85135db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/Sajjad-Ahmad-phy/Final-Year-Project\n",
      " * branch            main       -> FETCH_HEAD\n"
     ]
    }
   ],
   "source": [
    "!git pull origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8f32c5",
   "metadata": {},
   "source": [
    "###### A main function from where the whole class or TSP-Simulation be controlled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6e3bad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'Encoding Layer.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of '.ipynb_checkpoints/Parallel Processing in Python-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of '.ipynb_checkpoints/TSP-4 QNN-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'Parallel Processing in Python.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'TSP-4 QNN.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 4332015] Your commit message\n",
      " 6 files changed, 1064 insertions(+), 612 deletions(-)\n",
      " create mode 100644 .ipynb_checkpoints/Parallel Processing in Python-checkpoint.ipynb\n",
      " rename .ipynb_checkpoints/{TSP-QNN-checkpoint.ipynb => TSP-4 QNN-checkpoint.ipynb} (100%)\n",
      " create mode 100644 Parallel Processing in Python.ipynb\n",
      " create mode 100644 TSP-4 QNN.ipynb\n",
      " delete mode 100644 TSP-QNN.ipynb\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"Your commit message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e9542fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch 'main' set up to track 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/Sajjad-Ahmad-phy/Final-Year-Project.git\n",
      "   085d676..4332015  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5e79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
