{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb94cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [0, 2, 3, 4, 0, 6, 7, 8, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37700ca",
   "metadata": {},
   "source": [
    "2%3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49652d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0168c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import *\n",
    "from qiskit.circuit import parameter\n",
    "from qiskit.circuit import ParameterVector, Parameter\n",
    "from qiskit.visualization import plot_histogram\n",
    "from IPython.core.display import Latex\n",
    "from typing import Optional\n",
    "from qiskit_algorithms.optimizers import ADAM, Optimizer, COBYLA\n",
    "from qiskit_algorithms.gradients import SPSAEstimatorGradient\n",
    "from qiskit_aer import AerSimulator, StatevectorSimulator\n",
    "import numpy as np\n",
    "import ot\n",
    "import re\n",
    "from qiskit.circuit.library.standard_gates import RXGate, RYGate, RZGate, RZZGate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da7788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c716c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3     # Number of cities\n",
    "beta_para = (2 * np.pi * np.random.rand(1))[0]         # Beta parameters\n",
    "theta1 = (2 * np.pi * np.random.rand(1))        # Perceptron layers 1st parameters\n",
    "theta2 = (2 * np.pi * np.random.rand(1))   # Perceptron layers 2nd parameters\n",
    "alpha = (2 * np.pi * np.random.rand(1))       # Alpha parameters for pooling layer\n",
    "loss = 0\n",
    "\n",
    "# initial_point = np.array([beta_para for i in range(n*n)]+[theta1[0] for i in range(n*n)]+\n",
    "#                          [theta2[0] for i in range(n*n)]+[alpha[0] for i in range(n*n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca30dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_c = np.array([[0, 12, 13],\n",
    "                [21, 0, 23],\n",
    "                [31, 32, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cb431b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'000111101': 1,\n",
       " '100011100': 1,\n",
       " '111011101': 1,\n",
       " '011011000': 1,\n",
       " '001001101': 1}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc = QuantumCircuit(9)\n",
    "\n",
    "qc.h([i for i in range(9)])\n",
    "qc.ry(m_c[0][0], 0)\n",
    "qc.ry(m_c[1][1], 4)\n",
    "qc.ry(m_c[2][2], 8)\n",
    "\n",
    "rzz = []\n",
    "for i in range(len(m_c[0])):\n",
    "    for j in range(len(m_c[1])):\n",
    "        if i != j:\n",
    "            rzz.append(RZZGate(m_c[i][j]))\n",
    " \n",
    "qc.append(rzz[0], [0, 1])\n",
    "qc.append(rzz[1], [0, 2])\n",
    "\n",
    "qc.append(rzz[2], [3, 4])\n",
    "qc.append(rzz[3], [3, 5])\n",
    "\n",
    "qc.append(rzz[4], [6, 7])\n",
    "qc.append(rzz[5], [6, 8])\n",
    "\n",
    "qc.measure_all()\n",
    "simulator = AerSimulator()\n",
    "result= simulator.run(transpile(qc, simulator), shots = 5).result()\n",
    "result.get_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "005c857d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$(-0.9999608264 - 0.0088513093 i) |110000110\\rangle$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator = Aer.get_backend('statevector_simulator')\n",
    "result = execute(qc, simulator).result()\n",
    "statevector = result.get_statevector()\n",
    "statevector.draw('latex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c08243",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSP_Solver:\n",
    "    def __init__(self, reference_circuit, variational_circuit,MCRX, n, K, theta1, theta2, alpha, matching_matrix):\n",
    "        self.ref_cir = reference_circuit\n",
    "        self.var_cir = variational_circuit\n",
    "        self.MCRX = MCRX\n",
    "        self.n = n\n",
    "        self.n1 = n*n  # Squared of number of cities\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.theta1 = theta1\n",
    "        self.theta2 = theta2\n",
    "        self.matching_matrix = matching_matrix  # A constraint matrix for matching with the ground truth\n",
    "    \n",
    "    \"Creating an object of encoding layer\"\n",
    "    def encoding_layer(self):\n",
    "        self.ref_cir.ry(m_c[0][0], 0)\n",
    "        self.ref_cir.ry(m_c[1][1], 4)\n",
    "        self.ref_cir.ry(m_c[2][2], 8)\n",
    "\n",
    "        rzz = []\n",
    "        for i in range(len(m_c[0])):\n",
    "            for j in range(len(m_c[1])):\n",
    "                if i != j:\n",
    "                    rzz.append(RZZGate(m_c[i][j]))\n",
    "\n",
    "        self.ref_cir.append(rzz[0], [0, 1])\n",
    "        self.ref_cir.append(rzz[1], [0, 2])\n",
    "\n",
    "        self.ref_cir.append(rzz[2], [3, 4])\n",
    "        self.ref_cir.append(rzz[3], [3, 5])\n",
    "\n",
    "        self.ref_cir.append(rzz[4], [6, 7])\n",
    "        self.ref_cir.append(rzz[5], [6, 8])\n",
    "        self.ref_cir.barrier()\n",
    "            \n",
    "            \n",
    "    \"Defining contraint layer\"\n",
    "    def constraint_layer(self): \n",
    "        self.var_cir.append(self.MCRX, [1, 2, 3, 6, 0])    # rotation on qbit_1\n",
    "        self.var_cir.append(self.MCRX, [0, 2, 4, 7, 1])    # rotation on qbit_2\n",
    "        self.var_cir.append(self.MCRX, [0, 1, 5, 8, 2])    # rotation on qbit_3\n",
    "        self.var_cir.append(self.MCRX, [0, 6, 4, 5, 3])    # rotation on qbit_4\n",
    "        self.var_cir.append(self.MCRX, [1, 7, 3, 5, 4])    # rotation on qbit_5\n",
    "        self.var_cir.append(self.MCRX, [2, 3, 4, 8, 5])    # rotation on qbit_6\n",
    "        self.var_cir.append(self.MCRX, [0, 3, 7, 8, 6])    # rotation on qbit_7\n",
    "        self.var_cir.append(self.MCRX, [1, 4, 6, 8, 7])    # rotation on qbit_8\n",
    "        self.var_cir.append(self.MCRX, [6, 7, 2, 5, 8])    # rotation on qbit_9\n",
    "        self.var_cir.barrier()\n",
    "    \n",
    "    \"Perceptron layer\"\n",
    "    def perceptron_layer(self):\n",
    "        rz = RZGate(self.theta1[0])\n",
    "        ry = RYGate(self.theta2[0])\n",
    "        for q in range(self.n1):\n",
    "            self.var_cir.append(rz, [q])\n",
    "            self.var_cir.append(ry, [q])\n",
    "        self.var_cir.barrier()\n",
    "               \n",
    "    'Pooling Layer'\n",
    "    def pooling_layer(self):\n",
    "        ry = RYGate(self.alpha[0])\n",
    "        for q in range(self.n1):\n",
    "            self.var_cir.append(ry, [q])\n",
    "    \n",
    "    'composing the reference and variational circuits'\n",
    "    # The circuit can be visualized as well from here.\n",
    "    def ansatz(self):\n",
    "        ansat = self.ref_cir.compose(self.var_cir)\n",
    "        ansat.measure_all()\n",
    "        return ansat\n",
    "    \n",
    "    'Statvector simulating'\n",
    "    def statevect(self):\n",
    "        simulator = StatevectorSimulator()\n",
    "        result= simulator.run(transpile(self.ansatz(), simulator), shots = 1000).result()\n",
    "        statevector = result.get_statevector()\n",
    "        return statevector.draw('latex')\n",
    "    \n",
    "    'Reshaping result to matrix'\n",
    "    def x_matrix(self):\n",
    "        latex_string = self.statevect().data     # Stores the statevector as a latex string5\n",
    "        latex_list = list(latex_string)        # This object stores the statevector as a list\n",
    "        \n",
    "        'Extracting only the states of the qubits'\n",
    "        a = latex_list.index('|')\n",
    "        b = latex_list.index('\\\\')\n",
    "        y = latex_list[a+1:b]\n",
    "        y1 = np.array([int(i) for i in y])\n",
    "        Y1 = y1.reshape(self.n, self.n)  # Reshaping the measured states of qubits to a matrix \n",
    "        \n",
    "        # Define the size of marginals\n",
    "        n = Y1.shape[0]\n",
    "        m = Y1.shape[1]\n",
    "        \n",
    "        # Define the cost matrix with the matching constraint\n",
    "        cost_matrix = np.multiply(Y1, self.matching_matrix) # Element-wise multiplication to zero out non-matching elements\n",
    "\n",
    "        # Apply Sinkhorn algorithm to converge to a doubly stochastic matrix with the matching constraint\n",
    "        X_ds = ot.sinkhorn(np.ones(n) / n, np.ones(m) / m, cost_matrix, reg=0.01)\n",
    "        return X_ds\n",
    "    \n",
    "    def cost_fun(self, loss):\n",
    "        \"\"\"Cost function of circuit parameters on training data.\n",
    "            The optimizer will attempt to minimize this.\"\"\"\n",
    "        X = list(self.matching_matrix.flatten())\n",
    "        Y = list(self.x_matrix().flatten())\n",
    "        for i in range(len(X)):\n",
    "            loss += (-X[i]*np.log(Y[i]) + (1-X[i])*np.log(1-Y[i]))\n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb4d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7c13a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_pass_obj_fun(TSP, loss):\n",
    "    TSP.encoding_layer()\n",
    "    TSP.constraint_layer()\n",
    "    TSP.perceptron_layer()\n",
    "    TSP.pooling_layer()\n",
    "    TSP.ansatz()\n",
    "    TSP.statevect()\n",
    "    TSP.x_matrix()\n",
    "    obj = TSP.cost_fun(loss)\n",
    "    return obj\n",
    "    \n",
    "    \n",
    "# Define the matching constraint\n",
    "m_c = np.array([[0, 1, 0],\n",
    "                [1, 0, 0],\n",
    "                [0, 0, 1]])\n",
    "\n",
    "reference_circuit = QuantumCircuit(n*n)      # Circuit to which data be encoded\n",
    "reference_circuit.h([i for i in range(n*n)])     \n",
    "variational_circuit = QuantumCircuit(n*n)     # Circuit for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f76dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c96f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(params):\n",
    "    # Extract theta1, theta2, alpha, and beta_para\n",
    "    theta1_values = params[1:10]  # Extract first 9 values for theta1\n",
    "    theta2_values = params[10:19]  # Extract next 9 values for theta2\n",
    "    alpha = params[19:28]  # Extract alpha\n",
    "    beta_para = params[0]  # Extract beta_para\n",
    "\n",
    "    # Set theta1 and theta2 values\n",
    "    TSP.theta1 = theta1_values\n",
    "    TSP.theta2 = theta2_values\n",
    "    TSP.alpha = alpha\n",
    "\n",
    "    # Update the beta_para for MCRX gate\n",
    "    beta_angle = beta_para  # Assuming you want to use the first value from beta_para\n",
    "    MCRX = RXGate(beta_angle).control(4, ctrl_state='0000')\n",
    "    TSP.MCRX = MCRX\n",
    "    \n",
    "    # Run the quantum neural network and compute loss\n",
    "    loss1 = call_pass_obj_fun(TSP, loss)  # Assuming call_pass_obj_fun returns the loss\n",
    "    return loss1\n",
    "\n",
    "def gradient_function(params):\n",
    "    gradient = np.zeros_like(params)\n",
    "    epsilon = 1e-6  # Small value for numerical differentiation\n",
    "\n",
    "    # Compute the objective function value at the initial point\n",
    "    initial_loss = objective_function(params)\n",
    "\n",
    "    # Iterate over each parameter and compute the gradient\n",
    "    for i in range(len(params)):\n",
    "        # Perturb the parameter by a small amount\n",
    "        params_plus = params.copy()\n",
    "        params_plus[i] += epsilon\n",
    "\n",
    "        # Compute the objective function value after perturbation\n",
    "        loss_plus = objective_function(params_plus)\n",
    "\n",
    "        # Compute the gradient for this parameter using finite differences\n",
    "        gradient[i] = (loss_plus - initial_loss) / epsilon\n",
    "\n",
    "    return gradient\n",
    "\n",
    "# Preparing the multi-controlled X rotational gate\n",
    "MCRX = RXGate(initial_point[0]).control(4, ctrl_state='0000')\n",
    "\n",
    "TSP = TSP_Solver(reference_circuit, variational_circuit, MCRX, n, K, initial_point[1:10], \n",
    "                 initial_point[10:19], initial_point[19:28], m_c)\n",
    "\n",
    "# Instantiate Adam optimizer\n",
    "adam_optimizer = ADAM(maxiter=1, tol=1e-06, lr=0.001, beta_1=0.9,\n",
    "                      beta_2=0.99, noise_factor=1e-08, eps=1e-10, amsgrad=False, snapshot_dir=None)\n",
    "\n",
    "# Run optimization\n",
    "optimal_params, optimal_value, num_iterations = adam_optimizer.minimize(objective_function, initial_point, gradient_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24299034",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal parameters:\", optimal_params)\n",
    "print(\"Optimal value (minimum loss):\", optimal_value)\n",
    "print(\"Number of iterations taken:\", num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d22352b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea115ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "940197aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(params, loss):\n",
    "    # Extract theta1, theta2, alpha, and beta_para\n",
    "    theta1_values = params[9:18]  # Extract first 9 values for theta1\n",
    "    theta2_values = params[18:27]  # Extract next 9 values for theta2\n",
    "    alpha = params[27:36]  # Extract alpha\n",
    "    beta_para = params[:1]  # Extract beta_para\n",
    "\n",
    "    # Set theta1 and theta2 values\n",
    "    TSP.theta1 = theta1_values\n",
    "    TSP.theta2 = theta2_values\n",
    "    TSP.alpha = alpha\n",
    "\n",
    "    # Update the beta_para for MCRX gate\n",
    "    beta_angle = beta_para[0]  # Assuming you want to use the first value from beta_para\n",
    "    MCRX = RXGate(beta_angle).control(4, ctrl_state='0000')\n",
    "    TSP.MCRX = MCRX\n",
    "    \n",
    "    # Run the quantum neural network and compute loss\n",
    "    loss = call_pass_obj_fun(TSP, loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621383e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d91d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_function(params):\n",
    "    gradient = np.zeros_like(params)\n",
    "    epsilon = 1e-6  # Small value for numerical differentiation\n",
    "\n",
    "    # Compute the objective function value at the initial point\n",
    "    initial_loss = objective_function(params, loss)\n",
    "\n",
    "    # Iterate over each parameter and compute the gradient\n",
    "    for i in range(len(params)):\n",
    "        # Perturb the parameter by a small amount\n",
    "        params_plus = params.copy()\n",
    "        params_plus[i] += epsilon\n",
    "\n",
    "        # Compute the objective function value after perturbation\n",
    "        loss_plus = objective_function(params_plus, loss)\n",
    "\n",
    "        # Compute the gradient for this parameter using finite differences\n",
    "        gradient[i] = (loss_plus - initial_loss) / epsilon\n",
    "\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ba9ad2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "objective_function() missing 1 required positional argument: 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19940\\2519988975.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Run optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0moptimal_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimal_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madam_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_point\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: objective_function() missing 1 required positional argument: 'loss'"
     ]
    }
   ],
   "source": [
    "#Preparing the multi-controlled X rotational gat\n",
    "MCRX=RXGate(beta_para).control(4, ctrl_state='0000')\n",
    "\n",
    "TSP = TSP_Solver(reference_circuit, variational_circuit, MCRX, n, K, theta1, theta2, alpha, m_c)\n",
    "\n",
    "initial_point = np.array([beta_para for i in range(n*n)]+[theta1[0] for i in range(n*n)]+\n",
    "                         [theta2[0] for i in range(n*n)]+[alpha[0] for i in range(n*n)])\n",
    "\n",
    "loss = 0\n",
    "# Instantiate Adam optimizer\n",
    "adam_optimizer = ADAM(maxiter=1, tol=1e-06, lr=0.001, beta_1=0.9,\n",
    "                      beta_2=0.99, noise_factor=1e-08, eps=1e-10, amsgrad=False, snapshot_dir=None)\n",
    "\n",
    "# Run optimization\n",
    "optimal_params, optimal_value, num_iterations = adam_optimizer.minimize(objective_function, initial_point, gradient_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e0fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal parameters:\", optimal_params)\n",
    "print(\"Optimal value (minimum loss):\", optimal_value)\n",
    "print(\"Number of iterations taken:\", num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74836df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "498f68f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix:\n",
      "[[1 1 0]\n",
      " [1 1 1]\n",
      " [0 1 1]]\n",
      "\n",
      "Sinkhorn Normalized Matrix:\n",
      "[[6.17945249e-01 3.82009646e-01 1.00110187e-09]\n",
      " [3.81977207e-01 2.36135771e-01 3.81977207e-01]\n",
      " [1.00110187e-09 3.82009646e-01 6.17945249e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999548964587294"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sinkhorn_normalization(matrix, epsilon=1e-3, max_iters=100, constraint_epsilon=1e-9):\n",
    "    assert matrix.shape[0] == matrix.shape[1], \"Input matrix must be square\"\n",
    "    \n",
    "    # Get the shape of the matrix\n",
    "    n = matrix.shape[0]\n",
    "    \n",
    "    # Initialize u and v vectors\n",
    "    u = np.ones(n)\n",
    "    v = np.ones(n)\n",
    "    \n",
    "    # Perform Sinkhorn iterations\n",
    "    for _ in range(max_iters):\n",
    "        u_new = 1 / (np.dot(matrix, v) + epsilon)\n",
    "        v_new = 1 / (np.dot(matrix.T, u_new) + epsilon)\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.allclose(u_new, u) and np.allclose(v_new, v):\n",
    "            break\n",
    "        \n",
    "        u = u_new\n",
    "        v = v_new\n",
    "    \n",
    "    # Compute the Sinkhorn normalized matrix\n",
    "    normalized_matrix = np.diag(u_new) @ matrix @ np.diag(v_new)\n",
    "    \n",
    "    # Apply constraint on zero terms\n",
    "    normalized_matrix[normalized_matrix < constraint_epsilon] = constraint_epsilon\n",
    "    \n",
    "    # Renormalize the matrix to ensure it remains doubly stochastic\n",
    "    row_sums = np.sum(normalized_matrix, axis=1)\n",
    "    col_sums = np.sum(normalized_matrix, axis=0)\n",
    "    normalized_matrix /= np.sqrt(np.outer(row_sums, col_sums))\n",
    "    \n",
    "    return normalized_matrix\n",
    "\n",
    "# Example usage\n",
    "# Define an input matrix\n",
    "m1 = np.array([[1, 1, 0],\n",
    "               [1, 1, 1],\n",
    "               [0, 1, 1]])\n",
    "\n",
    "# Perform Sinkhorn normalization with constraint on zero terms\n",
    "normalized_matrix = sinkhorn_normalization(m1)\n",
    "\n",
    "print(\"Original Matrix:\")\n",
    "print(m1)\n",
    "print(\"\\nSinkhorn Normalized Matrix:\")\n",
    "print(normalized_matrix)\n",
    "sum(normalized_matrix[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbbebc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
